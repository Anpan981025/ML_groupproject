{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5a64ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2a35c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24783, 6)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('dataset.csv', index_col = 'Unnamed: 0')\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba69a4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.index=[np.arange(24783)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60e87b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  hate_speech  offensive_language  neither  class  \\\n",
       "0      3            0                   0        3      2   \n",
       "1      3            0                   3        0      1   \n",
       "2      3            0                   3        0      1   \n",
       "3      3            0                   2        1      1   \n",
       "4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4df76e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, ..., 1, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=dataset['class'].values\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5e7c41",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebf51201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "stemmer = nltk.PorterStemmer()\n",
    "stopword = set(stopwords.words('english'))\n",
    "new_tweet=[]\n",
    "import string\n",
    "\n",
    "def data_preprocess(review):\n",
    "    review = re.sub(r'^\\s+|\\s+?$','',review) # remove leading and trailing whitespace\n",
    "    review = re.sub(r'@[\\w\\-]+', '', review) # remove mentions\n",
    "    review = re.sub(r'RT[\\s]+', '', review) #remove retweet text 'RT'\n",
    "    review = re.sub('[^a-zA-Z]',' ',review)#replace non-character with space\n",
    "    review = review.lower() #lower the text\n",
    "    review = re.sub('\\[.*?\\]', '', review)\n",
    "    review = re.sub('https?://\\S+|www\\.\\S+', '', review) # remove hyperlinks\n",
    "    review = re.sub(r'#', '', review) # remove hashtags\n",
    "    review = re.sub('[%s]' % re.escape(string.punctuation), '', review) # remove escape characters\n",
    "    review = re.sub('\\n', '', review)\n",
    "    review = re.sub('\\w*\\d\\w*', '', review)\n",
    "    review = [word for word in review.split(' ') if word not in stopword and word not in string.punctuation] #remove stopwords and punctuations and tokenize\n",
    "    review=\" \".join(review)\n",
    "    review = [stemmer.stem(word) for word in review.split(' ')] #use PorterStemmer\n",
    "    \n",
    "    review=\" \".join(review)\n",
    "    new_tweet.append(review)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c97a7000",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['processed_tweet'] = dataset['tweet'].apply(data_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fce3fb9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>processed_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>woman complain clean hous amp man alway take t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>boy dat cold tyga dwn bad cuffin dat hoe st place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>dawg ever fuck bitch start cri confus shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>look like tranni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>shit hear might true might faker bitch told ya</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
       "\n",
       "                                     processed_tweet  \n",
       "0  woman complain clean hous amp man alway take t...  \n",
       "1  boy dat cold tyga dwn bad cuffin dat hoe st place  \n",
       "2         dawg ever fuck bitch start cri confus shit  \n",
       "3                                   look like tranni  \n",
       "4     shit hear might true might faker bitch told ya  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[['tweet','processed_tweet']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4f4126",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc00db93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(dataset[\"processed_tweet\"].apply(lambda x: x.split(\" \")))]\n",
    "\n",
    "# training of the model\n",
    "doc2vec_model = Doc2Vec(documents,vector_size=200, window=2, min_count=1, workers=4)\n",
    "\n",
    "# transform each document (tweet) into a vector data\n",
    "doc2vec_features = dataset[\"processed_tweet\"].apply(lambda x: doc2vec_model.infer_vector(x.split(\" \"))).apply(pd.Series)\n",
    "doc2vec_features.columns = [\"doc2vec_vector_\" + str(x) for x in doc2vec_features.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a399d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc2vec_vector_0</th>\n",
       "      <th>doc2vec_vector_1</th>\n",
       "      <th>doc2vec_vector_2</th>\n",
       "      <th>doc2vec_vector_3</th>\n",
       "      <th>doc2vec_vector_4</th>\n",
       "      <th>doc2vec_vector_5</th>\n",
       "      <th>doc2vec_vector_6</th>\n",
       "      <th>doc2vec_vector_7</th>\n",
       "      <th>doc2vec_vector_8</th>\n",
       "      <th>doc2vec_vector_9</th>\n",
       "      <th>...</th>\n",
       "      <th>doc2vec_vector_190</th>\n",
       "      <th>doc2vec_vector_191</th>\n",
       "      <th>doc2vec_vector_192</th>\n",
       "      <th>doc2vec_vector_193</th>\n",
       "      <th>doc2vec_vector_194</th>\n",
       "      <th>doc2vec_vector_195</th>\n",
       "      <th>doc2vec_vector_196</th>\n",
       "      <th>doc2vec_vector_197</th>\n",
       "      <th>doc2vec_vector_198</th>\n",
       "      <th>doc2vec_vector_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>-0.005792</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>0.015952</td>\n",
       "      <td>-0.015845</td>\n",
       "      <td>-0.021174</td>\n",
       "      <td>0.022643</td>\n",
       "      <td>-0.004967</td>\n",
       "      <td>0.006594</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003230</td>\n",
       "      <td>-0.007095</td>\n",
       "      <td>0.034785</td>\n",
       "      <td>-0.013830</td>\n",
       "      <td>-0.010418</td>\n",
       "      <td>0.014935</td>\n",
       "      <td>0.010801</td>\n",
       "      <td>0.010530</td>\n",
       "      <td>-0.000150</td>\n",
       "      <td>0.004209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.014424</td>\n",
       "      <td>0.005881</td>\n",
       "      <td>0.005284</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.021418</td>\n",
       "      <td>-0.021799</td>\n",
       "      <td>-0.005721</td>\n",
       "      <td>0.055685</td>\n",
       "      <td>-0.010746</td>\n",
       "      <td>0.007668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032443</td>\n",
       "      <td>-0.008155</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>-0.022808</td>\n",
       "      <td>0.017549</td>\n",
       "      <td>0.017183</td>\n",
       "      <td>0.020983</td>\n",
       "      <td>-0.028478</td>\n",
       "      <td>-0.006098</td>\n",
       "      <td>0.007463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021725</td>\n",
       "      <td>0.006636</td>\n",
       "      <td>-0.006318</td>\n",
       "      <td>-0.006288</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>-0.010310</td>\n",
       "      <td>0.005514</td>\n",
       "      <td>0.005221</td>\n",
       "      <td>0.014855</td>\n",
       "      <td>-0.034314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013837</td>\n",
       "      <td>0.009467</td>\n",
       "      <td>-0.008689</td>\n",
       "      <td>-0.005960</td>\n",
       "      <td>-0.024160</td>\n",
       "      <td>-0.016575</td>\n",
       "      <td>-0.001938</td>\n",
       "      <td>0.016695</td>\n",
       "      <td>0.007768</td>\n",
       "      <td>0.009809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.007255</td>\n",
       "      <td>0.004057</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.015086</td>\n",
       "      <td>0.009713</td>\n",
       "      <td>-0.001777</td>\n",
       "      <td>0.006810</td>\n",
       "      <td>0.007078</td>\n",
       "      <td>-0.006692</td>\n",
       "      <td>0.007976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>0.010969</td>\n",
       "      <td>-0.002338</td>\n",
       "      <td>-0.006479</td>\n",
       "      <td>0.009347</td>\n",
       "      <td>-0.001338</td>\n",
       "      <td>-0.000663</td>\n",
       "      <td>-0.009548</td>\n",
       "      <td>0.011847</td>\n",
       "      <td>-0.002020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022911</td>\n",
       "      <td>-0.002314</td>\n",
       "      <td>-0.006026</td>\n",
       "      <td>0.003586</td>\n",
       "      <td>0.013179</td>\n",
       "      <td>-0.017380</td>\n",
       "      <td>0.002289</td>\n",
       "      <td>0.038162</td>\n",
       "      <td>0.012686</td>\n",
       "      <td>-0.027958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005699</td>\n",
       "      <td>-0.004371</td>\n",
       "      <td>-0.002189</td>\n",
       "      <td>-0.005577</td>\n",
       "      <td>-0.015894</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.015489</td>\n",
       "      <td>0.001899</td>\n",
       "      <td>-0.007307</td>\n",
       "      <td>0.005237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>-0.007706</td>\n",
       "      <td>-0.015174</td>\n",
       "      <td>-0.005996</td>\n",
       "      <td>0.029347</td>\n",
       "      <td>0.018690</td>\n",
       "      <td>-0.007605</td>\n",
       "      <td>-0.002446</td>\n",
       "      <td>0.078190</td>\n",
       "      <td>-0.026010</td>\n",
       "      <td>0.037534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067985</td>\n",
       "      <td>-0.016618</td>\n",
       "      <td>-0.010740</td>\n",
       "      <td>-0.017850</td>\n",
       "      <td>0.045248</td>\n",
       "      <td>0.034561</td>\n",
       "      <td>0.020894</td>\n",
       "      <td>-0.059704</td>\n",
       "      <td>-0.011045</td>\n",
       "      <td>-0.033884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>0.008493</td>\n",
       "      <td>0.009701</td>\n",
       "      <td>-0.003325</td>\n",
       "      <td>0.012578</td>\n",
       "      <td>0.013831</td>\n",
       "      <td>-0.012190</td>\n",
       "      <td>-0.007050</td>\n",
       "      <td>0.030642</td>\n",
       "      <td>0.005496</td>\n",
       "      <td>-0.015047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003315</td>\n",
       "      <td>-0.006145</td>\n",
       "      <td>0.004209</td>\n",
       "      <td>-0.014305</td>\n",
       "      <td>-0.008194</td>\n",
       "      <td>-0.000293</td>\n",
       "      <td>0.004412</td>\n",
       "      <td>-0.000980</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.009077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>0.021856</td>\n",
       "      <td>0.004335</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>0.004199</td>\n",
       "      <td>0.020049</td>\n",
       "      <td>-0.011674</td>\n",
       "      <td>-0.005598</td>\n",
       "      <td>0.010822</td>\n",
       "      <td>0.025686</td>\n",
       "      <td>-0.038614</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007026</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>-0.004181</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>-0.026948</td>\n",
       "      <td>-0.017452</td>\n",
       "      <td>0.018596</td>\n",
       "      <td>0.013746</td>\n",
       "      <td>0.002697</td>\n",
       "      <td>0.034742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>-0.003960</td>\n",
       "      <td>0.014977</td>\n",
       "      <td>0.013875</td>\n",
       "      <td>-0.008794</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.043789</td>\n",
       "      <td>-0.008657</td>\n",
       "      <td>0.008219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028393</td>\n",
       "      <td>-0.008763</td>\n",
       "      <td>-0.006103</td>\n",
       "      <td>-0.011387</td>\n",
       "      <td>0.011383</td>\n",
       "      <td>0.015028</td>\n",
       "      <td>0.011428</td>\n",
       "      <td>-0.023675</td>\n",
       "      <td>-0.003432</td>\n",
       "      <td>-0.003554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>-0.049084</td>\n",
       "      <td>-0.014873</td>\n",
       "      <td>-0.007417</td>\n",
       "      <td>0.049132</td>\n",
       "      <td>0.044908</td>\n",
       "      <td>-0.021583</td>\n",
       "      <td>-0.004525</td>\n",
       "      <td>0.119379</td>\n",
       "      <td>-0.058876</td>\n",
       "      <td>0.101879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113335</td>\n",
       "      <td>-0.020255</td>\n",
       "      <td>-0.002151</td>\n",
       "      <td>-0.039555</td>\n",
       "      <td>0.101329</td>\n",
       "      <td>0.070977</td>\n",
       "      <td>0.027850</td>\n",
       "      <td>-0.108203</td>\n",
       "      <td>-0.020526</td>\n",
       "      <td>-0.055355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows Ã— 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       doc2vec_vector_0  doc2vec_vector_1  doc2vec_vector_2  doc2vec_vector_3  \\\n",
       "0              0.002370          0.001721         -0.005792         -0.000094   \n",
       "1             -0.014424          0.005881          0.005284          0.018182   \n",
       "2              0.021725          0.006636         -0.006318         -0.006288   \n",
       "3             -0.007255          0.004057          0.001803          0.015086   \n",
       "4              0.022911         -0.002314         -0.006026          0.003586   \n",
       "...                 ...               ...               ...               ...   \n",
       "24778         -0.007706         -0.015174         -0.005996          0.029347   \n",
       "24779          0.008493          0.009701         -0.003325          0.012578   \n",
       "24780          0.021856          0.004335          0.017400          0.004199   \n",
       "24781          0.001357          0.002004         -0.003960          0.014977   \n",
       "24782         -0.049084         -0.014873         -0.007417          0.049132   \n",
       "\n",
       "       doc2vec_vector_4  doc2vec_vector_5  doc2vec_vector_6  doc2vec_vector_7  \\\n",
       "0              0.015952         -0.015845         -0.021174          0.022643   \n",
       "1              0.021418         -0.021799         -0.005721          0.055685   \n",
       "2              0.000538         -0.010310          0.005514          0.005221   \n",
       "3              0.009713         -0.001777          0.006810          0.007078   \n",
       "4              0.013179         -0.017380          0.002289          0.038162   \n",
       "...                 ...               ...               ...               ...   \n",
       "24778          0.018690         -0.007605         -0.002446          0.078190   \n",
       "24779          0.013831         -0.012190         -0.007050          0.030642   \n",
       "24780          0.020049         -0.011674         -0.005598          0.010822   \n",
       "24781          0.013875         -0.008794          0.000261          0.043789   \n",
       "24782          0.044908         -0.021583         -0.004525          0.119379   \n",
       "\n",
       "       doc2vec_vector_8  doc2vec_vector_9  ...  doc2vec_vector_190  \\\n",
       "0             -0.004967          0.006594  ...           -0.003230   \n",
       "1             -0.010746          0.007668  ...            0.032443   \n",
       "2              0.014855         -0.034314  ...           -0.013837   \n",
       "3             -0.006692          0.007976  ...            0.005074   \n",
       "4              0.012686         -0.027958  ...            0.005699   \n",
       "...                 ...               ...  ...                 ...   \n",
       "24778         -0.026010          0.037534  ...            0.067985   \n",
       "24779          0.005496         -0.015047  ...            0.003315   \n",
       "24780          0.025686         -0.038614  ...           -0.007026   \n",
       "24781         -0.008657          0.008219  ...            0.028393   \n",
       "24782         -0.058876          0.101879  ...            0.113335   \n",
       "\n",
       "       doc2vec_vector_191  doc2vec_vector_192  doc2vec_vector_193  \\\n",
       "0               -0.007095            0.034785           -0.013830   \n",
       "1               -0.008155            0.000367           -0.022808   \n",
       "2                0.009467           -0.008689           -0.005960   \n",
       "3                0.010969           -0.002338           -0.006479   \n",
       "4               -0.004371           -0.002189           -0.005577   \n",
       "...                   ...                 ...                 ...   \n",
       "24778           -0.016618           -0.010740           -0.017850   \n",
       "24779           -0.006145            0.004209           -0.014305   \n",
       "24780            0.000277           -0.004181            0.000430   \n",
       "24781           -0.008763           -0.006103           -0.011387   \n",
       "24782           -0.020255           -0.002151           -0.039555   \n",
       "\n",
       "       doc2vec_vector_194  doc2vec_vector_195  doc2vec_vector_196  \\\n",
       "0               -0.010418            0.014935            0.010801   \n",
       "1                0.017549            0.017183            0.020983   \n",
       "2               -0.024160           -0.016575           -0.001938   \n",
       "3                0.009347           -0.001338           -0.000663   \n",
       "4               -0.015894            0.000340            0.015489   \n",
       "...                   ...                 ...                 ...   \n",
       "24778            0.045248            0.034561            0.020894   \n",
       "24779           -0.008194           -0.000293            0.004412   \n",
       "24780           -0.026948           -0.017452            0.018596   \n",
       "24781            0.011383            0.015028            0.011428   \n",
       "24782            0.101329            0.070977            0.027850   \n",
       "\n",
       "       doc2vec_vector_197  doc2vec_vector_198  doc2vec_vector_199  \n",
       "0                0.010530           -0.000150            0.004209  \n",
       "1               -0.028478           -0.006098            0.007463  \n",
       "2                0.016695            0.007768            0.009809  \n",
       "3               -0.009548            0.011847           -0.002020  \n",
       "4                0.001899           -0.007307            0.005237  \n",
       "...                   ...                 ...                 ...  \n",
       "24778           -0.059704           -0.011045           -0.033884  \n",
       "24779           -0.000980            0.000244            0.009077  \n",
       "24780            0.013746            0.002697            0.034742  \n",
       "24781           -0.023675           -0.003432           -0.003554  \n",
       "24782           -0.108203           -0.020526           -0.055355  \n",
       "\n",
       "[24783 rows x 200 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a16dc219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find max length of tweets dataset['processed_tweet']\n",
    "maxlen = -1\n",
    "for i, rev in enumerate(new_tweet):\n",
    "    tweet = rev.split()\n",
    "    if (len(tweet)>maxlen):\n",
    "        maxlen = len(tweet)\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bc2fdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_tweet = dataset['processed_tweet'].apply(lambda x:x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a69ed27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(tokenized_tweet)\n",
    "X = tokenizer.texts_to_sequences(tokenized_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0393592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24783, 28)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X = pad_sequences(X, padding='pre',maxlen=28)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "577f239e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19219"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = doc2vec_model.wv.key_to_index.keys()\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7293f958",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec_dict = {}\n",
    "for word in vocab:\n",
    "    word_vec_dict[word] = doc2vec_model.wv.get_vector(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a685b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.41023266,  0.3140282 , -0.04731553, ..., -0.15827499,\n",
       "         0.05977133,  0.32247439],\n",
       "       [ 0.36642444,  0.22944017, -0.1887005 , ..., -0.24390805,\n",
       "         0.02027663,  0.20542215],\n",
       "       ...,\n",
       "       [-0.00754355,  0.00188093,  0.00050273, ..., -0.03198026,\n",
       "        -0.00378917, -0.01197336],\n",
       "       [ 0.01364848, -0.00199141,  0.00249187, ..., -0.0145713 ,\n",
       "        -0.00096715, -0.00157534],\n",
       "       [ 0.00086747, -0.00748972,  0.00301885, ..., -0.01123519,\n",
       "        -0.00317441, -0.00527421]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "w_matrix = np.zeros((vocab_size, 200))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedd_vector = word_vec_dict.get(word)\n",
    "    if embedd_vector is not None:\n",
    "        w_matrix[i] = embedd_vector\n",
    "\n",
    "w_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3d3dba",
   "metadata": {},
   "source": [
    "## LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "036ef129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten, Dropout, Dense, LSTM, Embedding, Activation, Bidirectional\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.initializers import Constant\n",
    "from keras.layers.convolutional import MaxPooling1D, Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b0e58d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = vocab_size, output_dim = 200, input_length = maxlen, embeddings_initializer=Constant(w_matrix),trainable=False)) \n",
    "model.add(Dropout(0.2)) #0.2\n",
    "\n",
    "model.add(Bidirectional(LSTM(64))) #64\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1, activation = 'linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40185611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 28, 200)           3843800   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 28, 200)           0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 128)              135680    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,991,961\n",
      "Trainable params: 148,161\n",
      "Non-trainable params: 3,843,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8bdc550a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d315bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "620/620 [==============================] - 14s 17ms/step - loss: -1.5522 - accuracy: 0.7632 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 2/50\n",
      "620/620 [==============================] - 10s 17ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 3/50\n",
      "620/620 [==============================] - 10s 17ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 4/50\n",
      "620/620 [==============================] - 10s 17ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 5/50\n",
      "620/620 [==============================] - 10s 17ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 6/50\n",
      "620/620 [==============================] - 11s 17ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 7/50\n",
      "620/620 [==============================] - 11s 17ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 8/50\n",
      "620/620 [==============================] - 11s 17ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 9/50\n",
      "620/620 [==============================] - 11s 17ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 10/50\n",
      "620/620 [==============================] - 11s 17ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 11/50\n",
      "620/620 [==============================] - 11s 18ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 12/50\n",
      "620/620 [==============================] - 12s 20ms/step - loss: -1.6809 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 13/50\n",
      "620/620 [==============================] - 13s 21ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 14/50\n",
      "620/620 [==============================] - 13s 22ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 15/50\n",
      "620/620 [==============================] - 14s 23ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 16/50\n",
      "620/620 [==============================] - 14s 23ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 17/50\n",
      "620/620 [==============================] - 14s 23ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 18/50\n",
      "620/620 [==============================] - 14s 23ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 19/50\n",
      "620/620 [==============================] - 14s 23ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 20/50\n",
      "620/620 [==============================] - 14s 23ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 21/50\n",
      "620/620 [==============================] - 14s 23ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 22/50\n",
      "620/620 [==============================] - 14s 23ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 23/50\n",
      "620/620 [==============================] - 14s 23ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 24/50\n",
      "620/620 [==============================] - 14s 23ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 25/50\n",
      "620/620 [==============================] - 14s 23ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 26/50\n",
      "620/620 [==============================] - 14s 23ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 27/50\n",
      "620/620 [==============================] - 14s 23ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 28/50\n",
      "620/620 [==============================] - 14s 23ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 29/50\n",
      "620/620 [==============================] - 14s 23ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 30/50\n",
      "620/620 [==============================] - 14s 23ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 31/50\n",
      "620/620 [==============================] - 14s 23ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 32/50\n",
      "620/620 [==============================] - 14s 23ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 33/50\n",
      "620/620 [==============================] - 14s 23ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 34/50\n",
      "620/620 [==============================] - 14s 23ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 35/50\n",
      "620/620 [==============================] - 14s 23ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 36/50\n",
      "620/620 [==============================] - 14s 23ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771s: -1.662 - ETA: 0s - loss: -1.6834 - accuracy: 0.77\n",
      "Epoch 37/50\n",
      "620/620 [==============================] - 14s 23ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 38/50\n",
      "620/620 [==============================] - 14s 23ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 39/50\n",
      "620/620 [==============================] - 15s 23ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 40/50\n",
      "620/620 [==============================] - 14s 23ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 41/50\n",
      "620/620 [==============================] - 14s 23ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 42/50\n",
      "620/620 [==============================] - 13s 21ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 43/50\n",
      "620/620 [==============================] - 13s 21ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 44/50\n",
      "620/620 [==============================] - 13s 21ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 45/50\n",
      "620/620 [==============================] - 13s 21ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 46/50\n",
      "620/620 [==============================] - 13s 21ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 47/50\n",
      "620/620 [==============================] - 13s 21ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 48/50\n",
      "620/620 [==============================] - 13s 21ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 49/50\n",
      "620/620 [==============================] - 13s 21ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n",
      "Epoch 50/50\n",
      "620/620 [==============================] - 13s 21ms/step - loss: -1.6814 - accuracy: 0.7736 - val_loss: -1.6827 - val_accuracy: 0.7771\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "hist = model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs = epochs,\n",
    "                 batch_size = batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6095cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
